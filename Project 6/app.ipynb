{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import collections\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1942cea3ee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendownload dataset (Running di terminal wsl)\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet  # green_tripdata\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet    #fhv_tripdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meload file yang telah terdownload\n",
    "df = spark.read \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .parquet(r\"D:\\13. Iykra Data Felowship\\Project\\Project 6\\green_tripdata_2021-02.parquet\")      \n",
    "\n",
    "df2 = spark.read \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .parquet(r\"D:\\13. Iykra Data Felowship\\Project\\Project 6\\fhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan Quey SQL di Spark\n",
    "\n",
    "df.createOrReplaceTempView('green')            # Cara2 : df.registerTempTable('taxi')\n",
    "df2.createOrReplaceTempView('fhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2021-02-01 07:34:03|  2021-02-01 07:51:58|                 N|       1.0|         130|         205|            5.0|         3.66|       14.0|  0.5|    0.5|      10.0|         0.0|     null|                  0.3|        25.3|         1.0|      1.0|                 0.0|\n",
      "|       2| 2021-02-01 07:04:00|  2021-02-01 07:10:30|                 N|       1.0|         152|         244|            1.0|          1.1|        6.5|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|         7.8|         2.0|      1.0|                 0.0|\n",
      "|       2| 2021-02-01 07:18:51|  2021-02-01 07:34:06|                 N|       1.0|         152|          48|            1.0|         4.93|       16.5|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|       20.55|         2.0|      1.0|                2.75|\n",
      "|       2| 2021-02-01 07:53:27|  2021-02-01 08:11:41|                 N|       1.0|         152|         241|            1.0|          6.7|       21.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|        22.3|         2.0|      1.0|                 0.0|\n",
      "|       2| 2021-02-01 07:57:46|  2021-02-01 08:06:44|                 N|       1.0|          75|          42|            1.0|         1.89|        8.5|  0.5|    0.5|      2.45|         0.0|     null|                  0.3|       12.25|         1.0|      1.0|                 0.0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show database green taxi trip records\n",
    "\n",
    "spark.sql('select * from green').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 07:01:00|2021-02-01 08:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 07:55:40|2021-02-01 08:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:14:03|2021-02-01 07:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:27:48|2021-02-01 07:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 07:12:50|2021-02-01 07:26:38|        null|       225.0|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show data for hire vehicle trip records\n",
    "\n",
    "spark.sql(\"select * from fhv\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. How many taxi trips were there on February 15?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('lpep_pickup_datetime', f.to_date(df.lpep_pickup_datetime)) \\\n",
    "    .select(\"lpep_pickup_datetime\").where(\"lpep_pickup_datetime=='2021-02-15'\").count()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the longest trip for each day ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|lpep_pickup_datetime|max(trip_distance)|\n",
      "+--------------------+------------------+\n",
      "|          2009-01-01|               0.0|\n",
      "|          2021-02-01|             27.52|\n",
      "|          2021-02-02|              48.1|\n",
      "|          2021-02-03|             36.33|\n",
      "|          2021-02-04|         102620.98|\n",
      "|          2021-02-05|             36.37|\n",
      "|          2021-02-06|             38.75|\n",
      "|          2021-02-07|              90.0|\n",
      "|          2021-02-08|            5634.0|\n",
      "|          2021-02-09|             34.64|\n",
      "|          2021-02-10|           60382.7|\n",
      "|          2021-02-11|          43174.56|\n",
      "|          2021-02-12|          66659.27|\n",
      "|          2021-02-13|             47.79|\n",
      "|          2021-02-14|             58.03|\n",
      "|          2021-02-15|             44.04|\n",
      "|          2021-02-16|          16191.56|\n",
      "|          2021-02-17|          16240.75|\n",
      "|          2021-02-18|          29501.25|\n",
      "|          2021-02-19|             34.95|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip = df \\\n",
    "    .withColumn('lpep_pickup_datetime', f.to_date(df.lpep_pickup_datetime)) \\\n",
    "    .select(\"lpep_pickup_datetime\",\"trip_distance\") \\\n",
    "    .groupBy(\"lpep_pickup_datetime\") \\\n",
    "    .agg({'trip_distance':'max'}) \\\n",
    "    .orderBy('lpep_pickup_datetime').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find Top 5 Most frequent `dispatching_base_num` ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|dispatching_base_num|Count|\n",
      "+--------------------+-----+\n",
      "|              B00856|35077|\n",
      "|              B01312|33089|\n",
      "|              B01145|31114|\n",
      "|              B02794|30397|\n",
      "|              B03016|29794|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    `dispatching_base_num`,\n",
    "    COUNT(`dispatching_base_num`) AS `Count`\n",
    "FROM `fhv`\n",
    "GROUP BY `dispatching_base_num`\n",
    "ORDER BY `Count` DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Find Top 5 Most common location pairs (PUlocationID and DOlocationID) ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------+\n",
      "|PULocationID|DOLocationID|count(1)|\n",
      "+------------+------------+--------+\n",
      "|        62.0|        85.0|       2|\n",
      "|       169.0|       185.0|      29|\n",
      "|       119.0|       229.0|       3|\n",
      "|       246.0|       142.0|      11|\n",
      "|         7.0|       193.0|      69|\n",
      "+------------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    PULocationID,DOLocationID, COUNT(*)\n",
    "FROM fhv\n",
    "GROUP BY PULocationID, DOLocationID\n",
    "LIMIT 5;\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
